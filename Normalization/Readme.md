**The Objective of the paper is to understand Normalization in terms of optimization, how it helps in Generalization of model and in accelerating the speed of training a model.**

Some question it answer are follows

* What are the main motivations behind different normalization methods in DNNs, and how can we present a taxonomy
for understanding the similarities and differences between a wide
variety of approaches?

* How can we reduce the gap between the empirical success
of normalization techniques and our theoretical understanding of
them?

* What recent advances have been made in designing/tailoring
normalization techniques for different tasks, and what are the main
insights behind them?

Glossary: 
[Hessian Matrix](https://en.wikipedia.org/wiki/Hessian_matrix), [Fisher Information Matrix](https://en.wikipedia.org/wiki/Fisher_information), [Kronecker Product](https://en.wikipedia.org/wiki/Kronecker_product), 
